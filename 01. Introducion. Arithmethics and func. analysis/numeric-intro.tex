%\documentclass[14pt,a4paper]{extarticle}
\documentclass[12pt,a4paper]{article}
\usepackage[warn] {mathtext}
\usepackage[cp1251]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[top=2cm, bottom=2cm, marginparwidth=0pt, left=3cm, right=1.5cm]{geometry}
\usepackage{wasysym}


\newtheorem{theorem}{Теорема}[section]
\newtheorem{lemma}[theorem]{Лемма}
\newtheorem{proposition}[theorem]{Утверждение}
\newtheorem{corollary}[theorem]{Следствие}

\newenvironment{proof}[1][Доказательство.]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{definition}[1][Определение.]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Пример.]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Замечание.]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{problem}[1][Задача.]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\qed}{\nobreak \ifvmode \relax \else
      \ifdim\lastskip<1.5em \hskip-\lastskip
      \hskip1.5em plus0em minus0.5em \fi \nobreak
      \vrule height0.75em width0.5em depth0.25em\fi}

\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}

\begin{document}
%\pagestyle{empty}
\section{Основные понятия вычислительной математики}
\subsection{Предмет и особенности вычислительной математики}
{\bf Вычислительная математика} — раздел математики, включающий круг вопросов,
связанных с производством вычислений и использованием компьютеров. В более узком
понимании вычислительная математика — теория численных методов решения типовых
математических задач.

К задачам вычислительной математики относят:
\begin{itemize}
	\item решение систем линейных уравнений;
	\item решение систем нелинейных алгебраических уравнений;
	\item нахождение собственных значений и векторов матрицы;
	\item решение систем дифференциальных уравнений;
	\item решение интегральных уравнений;
	\item задачи аппроксимации;
	\item задачи интерполяции;
	\item задачи экстраполяции;
	\item задачи численной оптимизации.
\end{itemize}

Вычислительная математика (численный анализ) имеет отличия от других дисциплин 
и обладает определенными особенностями:
\begin{itemize}
	\item Она имеет дело как с дискретными, так и непрерывными объектами. Например, вместо отрезка прямой рассматривается набор точек, вместо непрерывной функции --- табличная функция, вместо производных --- их разностные аппроксимации. Дискретизация является необходимой для переноса математической модели в вычислительную среду. Таким образом, уже на этапе постановки задачи возникает некоторая погрешность.
	\item Численный анализ сталкивается с двумя типами ошибок: {\bf устранимыми} и {\bf неустранимыми}. При этом и устранимость ошибки лишь потенциальная (например, устранимая ошибка округления исчезает, если вычислительная машина является абсолютно точной). Неустранимая ошибка, как правило, заложена в самом вычислительном методе, математической модели реального объекта и входных данных.
	\item Задачи вычислительной математики обладают особым качеством --- {\bf обусловленностью}. Как правило, под обусловленность задачи понимается чувствительность ее решения к малым возмущениям входных данных.
	\item При решении вычислительных задач выбор метода является часто главным фактором, влияющим на качество решения.
	\item Для вычислительной математики важным фактором, влияющим на выбор способа решения задачи, является {\bf экономичность}, т.е. стремление минимизировать вычислительные затраты на решение.
\end{itemize}
Рассмотрим некоторые примеры, иллюстрирующие эти особенности.
\pagebreak

\subsection{Примеры}
\subsubsection{Обусловленность задачи}
\begin{example}
	Вычислить все корни уравнения 
	\[
		x^4 - 4x^3 + 8x^2 - 16x + 15.99999999 = \left(x - 2\right)^4 - 10^{-8} = 0~.
	\]
	Точное решение легко можно найти: $\displaystyle x_1 = 2.01, x_2 = 1.99,
	 x_{3,4} = 2 \pm 0.01i$. Однако, если точность вычислений больше, чем $10^{-8}$, то
	 с численной точки зрения из-за округления свободного члена решается уравнение 
	 $\displaystyle \left(x - 2\right)^4 = 0$, корни которого $\displaystyle x_{,2,3,4} = 2$.
\end{example}

\begin{example}
	Пусть решается задача Коши для ОДУ 2-го порядка:
	\[
		y''(x) = y(x), \qquad y(0) = 1, \quad y'(0) = -1.
	\]
	Общее решение имеет вид 
	\[
		y(x) = \frac{\left(y(0)+y'(0)\right)e^x + \left(y(0)-y'(0)\right)e^{-x}}{2}~.
	\]
	При заданных выше начальных условиях точное решение задачи
	$\displaystyle y(x) = e^{-x}$. Однако, если начальные условия заданы с малой ошибкой $\delta$, в решении появляется быстрорастущее слагаемое $\displaystyle \delta e^x$, которое искажает результат.
\end{example}

\begin{example}
	Пусть решается задача Коши:
	\[
		y' = 10y, \qquad y(x_0) = y_0, \quad x\in\left[0;1\right].
	\]
	Общее решение имеет вид $\displaystyle y(x) = y_0e^{10\left(x - x_0\right)}$.
	Пусть начальное условие известно лишь приближенно, т.е. $y(x_0) \approx y_0^*$.
	Решая эту приближенную задачу, мы найдем лишь $\displaystyle y^{*}(x) = y_0^{*}e^{10\left(x - x_0\right)}$, которое отличается от истинного решения на величину
	\[
		y^{*} - y  = \left(y^{*}_0 - y_0\right)e^{10\left(x - x_0\right)}.
	\]
	Пусть требуется обеспечить точность решения на всем промежутке не меньше заданного положительного $\varepsilon$. Нетрудно оценить
	\[
		\max_{x \in [0;1]} \left|y^{*}(x) - y(x)\right| = \left|y^{*}(1) - y(1)\right| = 
		\left|y^{*}_0 - y_0\right|e^{10\left(1 - x_0\right)}.
	\]
	Очевидно, требуемую точность решения можно получить, если точность задания начального условия $\displaystyle \delta \leqslant \varepsilon e^{-10}$.
	
	Таким образом, ограничения на точность начальных данных в $e^{10}$ раз выше требуемой точности решения и поэтому абсурдны.
\end{example}

\begin{example}
	Пусть решается система линейных алгебраических уравнений (СЛАУ) вида
	\[
		\left\{
			\begin{aligned}
				&x_1 + 10x_2 = 11 \\
				&100x_1 + 1001x_2 = 1101~.
			\end{aligned}
		\right.
	\]
	Легко проверить, что решение системы является пара $(1,1)$. В то же время 
	возмущенная система
	\[
		\left\{
			\begin{aligned}
				&x_1 + 10x_2 = 11.01 \\
				&100x_1 + 1001x_2 = 1101~.
			\end{aligned}
		\right.
	\]
	имеет решение $(11.01, 0)$, сильно отличающееся от решения невозмущенной.
\end{example}

\begin{example}
	Рассмотрим классический пример с многочленом
	\[
		P(x) = \left(x-1\right)\left(x-2\right)\dots\left(x-20\right).
	\]
	Если коэффициент при $x^{19}$ в канонической записи $P(x)$ изменить на величину порядка $10^{-7}$, корни многочлена очень сильно изменяться (в частности, появятся комплексные).
\end{example}

\subsubsection{Влияние выбора вычислительного метода}
\begin{example}
	Из анализа известно, что функция синус разлагается в ряд Тейлора, который сходится при любых значениях аргумента:
	\[
		\sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \dots~.
	\]
	Вычислим по этой формуле синус 30\textdegree, т.е. с точностью до четвертого
	знака, $x = 0.5236$. Суммируя члены ряда, большие $10^{-4}$, получим 
	$\sin(0.5236) = 0.5000$. 
	
	Пусть теперь $x = 25.66\,(1470\textdegree)$. Если вычисления производить с
	восемью значащими цифрами,  получим $\sin(25.25) \approx 24$, что невозможно
	по определению функции синус.
	
	{\bf Как можно исправить ситуацию?}
\end{example}

\begin{example}
	Рассмотрим достаточно известный интеграл:
	\[
		I_n = \int\limits_0^1{x^n e^{1-x}\,dx}, \quad n = 1,2,\dots
	\]
	Интегрируя по частям, легко можно получить следующую рекуррентную формулу:
	\[
		I_0 = e - 1, \qquad I_n = nI_{n-1} - 1, \quad n \geqslant 1~.
	\]
	Пусть в вычислениях мы значение $I_0$ округлили до шести значащих цифр. Легко проверить, что уже $I_9$ получится при этом отрицательным, что невозможно.
	
	{\bf Где накапливается погрешность?}
\end{example}

\begin{example}
	Рассмотрим рекуррентное соотношение:
	\[
		x_i = q x_{i-1}, \quad i \geqslant 0, \quad x_0 = a > 0, \quad q > 0~.
	\]
	Пусть при вычислениях из-за конечности разрядной сетки на $i$-ом шаге возникла
	ошибка округления и <<машинное>> решение исказилось: $x_i^M = x_i + \delta$.
	Тогда на следующем шаге
	\[
		x^M_{i+1} = q\left(x_i+\delta\right) = q x_i + q\delta = x_{i+1} + q\delta~.
	\]
	Очевидно, если $\left|q\right|>1$, то погрешность, возникшая из-за {\bf одной}
	ошибки округления, будет расти. Заметим, что в этом случае говорят, что 
	алгоритм {\bf неустойчив}.
\end{example}

\subsubsection{Экономичность метода}
\begin{example}
	Классический пример --- вычисление значений многочленов. Если вычислять
	значение 
	\[
		P(x) = a_nx^n + a_{n-1}x^{n-1} + \dots + a_1x + a_0
	\]
	в некоторой точке, подчиняясь стандартной форме записи многочлена, то нужно
	будет выполнить $\displaystyle n^2 + \left[\frac{n}{2}\right]$ умножений и $n$ 
	сложений.
	
	Однако еще в средние века китайским математикам был известен метод, который
	сейчас называется обычно схемой Горнера:
	\[
		P(x) = \left(\left(\dots\left(a_nx + a_{n-1}\right)x + a_{n-2}\right)x + \dots + a_0\right)~.
	\]
	Этот метод требует всего $n$ умножений и столько же сложений.
\end{example}

\begin{example}
	Решение СЛАУ с трехдиагональной матрицей каким-нибудь общим методом
	(методом Гаусса, например), требует порядка $n^3$ арифметических действий. Учет
	 структуры матрицы позволяет число операций уменьшить до $n$ (метод прогонки).
\end{example}

\subsubsection{Погрешность метода}
Воспользовавшись определением производной, запишем формулу приближенного
вычисления $f'(x)$:
\[
	f'(x) \approx \frac{f(x+h)-f(x)}{h}~.
\]
Чтобы оценить погрешность при вычислении по такой формуле, разложим функцию в ряд Тейлора и получим
\[
	\frac{f(x+h)-f(x)}{h} = \frac{\left[f(x) + hf'(x) + O(h^2)\right]-f(x)}{h} = 
	f'(x) + O(h).
\]
Таким образом, погрешность метода есть $O(h)$.

Если же повторить процедуру для следующей формулы:
\[
	f'(x) \approx \frac{f(x+h)-f(x-h)}{2h}~,
\]
то окажется, что погрешность метода $O(h^2)$. Заметим, что стремится сделать шаг $h$
как можно меньше бессмысленно. Легко можно показать, что существует некоторое оптимальное значение $h^*$ такое, что при дальнейшем уменьшении шага погрешность вычислений начнет расти за счет ошибок округления, хотя погрешность метода будет се меньше.

{\bf Докажите это и найдите $h^*$!}

\subsection{Элементы теории погрешностей}
\begin{definition}
	Пусть $u$ --- точное значение некоторой величины, а $u^*$ --- приближенное.
	Абсолютной погрешностью приближения $u^*$ называется величина $\Delta(u^*)$,
	удовлетворяющая неравенству $\displaystyle \left|u - u^*\right| \leqslant \Delta(u^*)$.
\end{definition}
\begin{definition}
	Относительной погрешностью приближения $u^*$ называется величина
	$\delta(u^*)$, 	удовлетворяющая неравенству
	$\displaystyle \left|\frac{u - u^*}{u^*}\right| \leqslant \delta(u^*)$.
\end{definition}
\begin{definition}
	Пусть $u = u(t_1, t_2, \dots, t_n)$ определена на множестве параметров $\Omega$.
	Предельной абсолютной погрешностью называется величина 
	\[
		\displaystyle D(u^*) = \sup_{(t_1,\dots,t_n) \in \Omega}\left|u(t_1,\dots,t_n) -
		 u^*\right|.
	\]
\end{definition}
\begin{definition}
	Пусть $u = u(t_1, t_2, \dots, t_n)$ определена на множестве параметров $\Omega$.
	Предельной относительной погрешностью называется величина 
	$\displaystyle \frac{D(u^*)}{\left|u^*\right|}$.
\end{definition}

Чтобы сформулировать следующее определение, необходимо напомнить один полезный факт из анализа.
\begin{proposition}
	Если функция $f(x) = f(x_1, \dots, x_n)$	 определена и дифференцируема в каждой
	точке области $\Omega$, то для каждой пары точек $x = (x_1, \dots, x_n) \in \Omega$
	и $x+\Delta x = (x_1+\Delta x_1, \dots, x_n+\Delta x_n) \in \Omega$ найдется такая
	точка $\xi = (\xi_1, \dots, \xi_n)$, лежащая на отрезке с концами в $x$ и
	$x+\Delta x$, что
	\[
		f(x+\Delta x) - f(x) = \sum\limits_{i=1}^n{\frac{\partial f(\xi)}{\partial x_i}\Delta x_i}.
	\]
	Это выражение называется формулой конечных приращений (Лагранжа).
\end{proposition}
Пусть теперь $u^* = u(t_1^*, \dots, t_n^*)$, причем 
$\left|t_i - t_i^*\right|\leqslant \Delta(t_i^*), \quad i=1,\dots,n$. Предполагая, что функция $u$ непрерывно дифференцируема, по формуле Лагранжа получаем
\[
	u(t_1, \dots, t_n) - u^* = \sum\limits_{i=1}^n{
	u'_{t_i}(t_1^* + \alpha(t_1-t_1^*), \dots, t_n^* + \alpha(t_n-t_n^*)) (t_i - t_i^*)},
\]
где $0 \leqslant \alpha \leqslant 1$. Если обозначить $\displaystyle 
\beta_i = \sup_{\Omega}{\left|u'_{t_i}(t_1, \dots, t_n)\right|}$, то получаем оценку 
\[
	\left|u(t_1, \dots, t_n) - u^*\right| \leqslant D_1(u^*) =
	\sum\limits_{i=1}^n{\beta_i\Delta(t_i^*)}.
\]
На практике используют и более грубую, линейную оценку погрешности:
\[
	\left|u(t_1, \dots, t_n) - u^*\right| \leqslant D_2(u^*) =
	\sum\limits_{i=1}^n{\left|u'_{t_i}(t_1^*, \dots, t_n^*)\right|\Delta(t_i^*)}.
\]
Действительно, в силу непрерывности частных производных, 
\[
	u'_{t_i}(t_1^* + \alpha(t_1-t_1^*), \dots, t_n^* + \alpha(t_n-t_n^*)) = 
	u'_{t_i}(t_1^*, \dots, t_n^*) + o(1).
\]
Поэтому $\displaystyle \beta_i = \left|u'_{t_i}(t_1^*, \dots, t_n^*)\right| + o(1)$, откуда
и следует требуемая оценка (вообще говоря, неверная).

Можно показать, что 
\begin{enumerate}
	\item Предельная абсолютная погрешность суммы или разности равна сумме
	предельных погрешностей.
	\item Предельная относительная погрешность произведения или частного
	приближенно равна сумме предельных относительных погрешностей.
\end{enumerate}
Рассмотрим несколько примеров.

\begin{example}
	Пусть $u(t) = t^{10}$, $t^* = 1$, $\Delta(t^*) = 0.001$. Найдем $D(t^*), D_1(t^*),
	D_2(t^*).$
	\[
		\begin{aligned}
			& u^* = (t^*)^{10} = 1, \qquad u'_t = 10t^9 ,  \\
			& u'_t(t^*+\alpha(t-t^*)) = 10(1+\alpha(t-1)), \\
			& \beta = \sup_{|t-1|\leqslant 0.001}\left|10t^9\right| = 10.09\dots.
		\end{aligned}
	\]
	Теперь легко вычислить
	\[
		\begin{aligned}
			& D(u^*) = \sup_{|t-1|\leqslant 0.001}\left|t^{10} - 1\right| = 0.010045\dots,\\
			& D_1(u^*) = \beta\Delta(t^*) = 0.01009\dots,\\
			& D_2(u^*) = \left|u'_t(t^*)\right|\Delta(t^*) = 0.01\dots.
		\end{aligned}
	\]	
	Как видим, в этом случае точная и линейная оценки погрешности не сильно
	отличаются.
\end{example}

\begin{example}
	Пусть теперь $\Delta(t^*) = 0.1$. В этом случае $\beta = \sup_{|t-1|\leqslant 0.1}\left|
	10t^9\right| = 23.5\dots$ и получаем
	\[
		\begin{aligned}
			& D(u^*) = \sup_{|t-1|\leqslant 0.1}\left|t^{10} - 1\right| = 1.59\dots, \\
			& D_1(u^*) = \beta\Delta(t^*) = 2.35\dots, \\
			& D_2(u^*) = \left|u'_t(t^*)\right|\Delta(t^*) = 1\dots.
		\end{aligned}
	\]	
	Здесь разница между оценками более заметна.
\end{example}

\begin{example}
	
	Пусть $F(x, p, q) = x^2 + px+q$. Оценим погрешность корней уравнения 
	$F(x,p,q)=~0$ при заданных приближенных значениях коэффициентов 
	$p^*, q^*$ и их погрешностях  $\Delta(p^*), \Delta(q^*)$.
	
	Пусть $x^*$ --- корень уравнения $F(x, p^*, q^*) = 0$. Чтобы найти предельные
	погрешности, необходимо знать $x'_p$ и $x'_q$. Дифференцируя уравнение
	относительно коэффициентов и разрешая получившуюся систему, получаем, что
	\[
		\begin{aligned}
			\frac{\partial x}{\partial p} = -\frac{\partial F}{\partial p}
			\left(\frac{\partial F}{\partial x}\right)^{-1}, \\
			\frac{\partial x}{\partial q} = -\frac{\partial F}{\partial q}
			\left(\frac{\partial F}{\partial x}\right)^{-1}.
		\end{aligned}
	\]
	Итак, $\displaystyle x'_p = -\frac{x}{2x+p}$ и $\displaystyle x'_q = -\frac{1}{2x+p}$.
	Тогда линейная оценка погрешности имеет вид
	\[
		D_2(x^*) = \frac{|x^*|\Delta(p^*)}{|2x^*+p^*|} +\frac{\Delta(q^*)}{|2x^*+p^*|}.
	\]
	Очевидно, что $D_2(x^*) \rightarrow \infty$ при $2x^*+p^* \rightarrow 0$, т.е. в
	некоторых случаях оценка может быть очень завышена.
\end{example}

\begin{problem}
	С каким числом знаков надо взять $\lg 2$, чтобы вычислить корни уравнения
	$x^2 -2x + \lg 2 = 0 $ с четырьмя верными знаками?
\end{problem}
\begin{problem}
	Найти относительную погрешность $\delta(u)$ вычисления функции 
	$u = xy^2z^3$ в точке $x^* = 37.1, y^* = 9.87, z^* = 6.052$, если известны
	погрешности координат $\Delta(x^*) = 0.3, \Delta(y^*) = 0.11, \Delta(z^*) = 0.016$.
\end{problem}

\begin{problem}
	Вычислить относительную погрешность в определении значения функции
	$\displaystyle u = \frac{x^2y^2}{z^4}$, если заданы $x^* = 37.1, y^* = 9.87, z^* =
	6.052$ с известными погрешностями  $\Delta(x^*) = 0.1, \Delta(y^*) = 0.05,
	\Delta(z^*) = 0.02$.
\end{problem}

\begin{problem}
	Найти абсолютную предельную погрешность $D(u^*)$, погрешность по
	производной $D_1(u^*)$ и линейную оценку погрешности $D_2(u^*)$
	для функций $u = \sin{t}$, $\displaystyle u =~\frac{1}{t^2-5t+6}$. Заданы точка
	приближения $t = t^*$ и 	погрешность $\Delta(t)$.
\end{problem}

\begin{problem}
	Пусть для вычисления функции $u(t)$ используется частичная сумма ряда
	Маклорена
	\[
		u(t) \approx u(0) + \frac{u'(0)}{1!}t + \frac{u''(0)}{2!}t^2 + \dots +
		\frac{u^{(n)}(0)}{n!}t^n,
	\]
	причем аргумент задан с погрешностью $\Delta t = 10^{-3}$.
	
	Найти $n$ такое, чтобы погрешность определения $u(t)$ не превышала $\Delta t$.
	Рассмотреть отрезки $t \in [0;1]$ и $t \in [10; 11]$. Оценить число слагаемых для
	функций $u = \cos t$ и $u = e^t$ на втором из отрезков.
\end{problem}

\pagebreak
\section{Близость и нормы}
Рассмотрим вопрос численного нахождения интеграла 
$\displaystyle I = \int\limits_a^b x(t)\,dt$. Можно заменить подынтегральную функцию
на более простую, интеграл от которой легко вычисляется. Главное, чтобы она была достаточно <<близка>> к исходной. А можно заменить интеграл суммой
$\displaystyle \sum\limits_i x(t_i)\Delta{t_i}$, которая тоже просто вычисляется. 

В первом случае приближенный метод вычисления основан на замене исходных данных
близкими к ним. Во втором случае заменяется на более простой сам оператор интегрирования. Очевидно, под близостью в этих двух случаях понимаются разные вещи.
Формализация этого интуитивного понятия составляет важную часть функционального
анализа. Напомним некоторые понятия, которые будут в дальнейшем часто использоваться.

\begin{definition}
	Метрическим пространством называется множество элементов $x$ произвольной
	природы, на котором введено расстояние (метрика) $\rho(x_1, x_2)$ между любыми
	двумя элементами множества, удовлетворяющее следующим условиям:
	\begin{enumerate}
		\item $\rho(x_1, x_2) \geqslant 0$.
		\item $\rho(x_1, x_2) = 0 \Leftrightarrow x_1 = x_2$.
		\item $\rho(x_1, x_2) = \rho(x_2, x_1)$.
		\item $\rho(x_1, x_3) \leqslant \rho(x_1, x_2) + \rho(x_2, x_3)$.
	\end{enumerate}
\end{definition}

\begin{definition}
	Последовательность элементов $x_n$ метрического пространства называется
	сходящейся (по метрике) к элементу $x^*$, если 
	$\displaystyle \lim\limits_{n\rightarrow\infty}{\rho(x_n, x^*)} = 0$.
\end{definition}

\begin{definition}
	Последовательность элементов $x_n$ метрического пространства называется
	фундаментальной, если для любого $\varepsilon > 0$ найдется такой номер 
	$k = k(\varepsilon)$, что $\rho(x_n, x_m) < \varepsilon$ при всех $n$ и $m$
	 больших $k$.
\end{definition}

\begin{definition}
	Метрическое пространство называется полным, если любая фундаментальная
	последовательность его элементов сходится к элементу того же пространства.
\end{definition}

Последнее качество очень важно для обоснования вычислительных методов.
Действительно, если некоторый итерационный метод имеет дело с элементами
неполного пространства (например, множеством рациональных чисел), то невозможно
обосновать его сходимость: даже если последовательность приближений является
фундаментальной, то она не обязательно сходится к элементу этого же пространства, т.е.
приближенное решение будет недопустимым с точки зрения постановки задачи.

\begin{definition}
	Линейное или векторное пространство $L$ над полем $P$--- это множество, на
	котором введены операции сложения и умножения на скаляр (элемент поля $P$),
	удовлетворяющие следующим условиям:
	\begin{enumerate}
		\item $(L, +)$ --- абелева группа.
		\item Операция умножения на скаляр ассоциативна.
		\item Умножение на единицу поля $P$ сохраняет элемент пространства
		 неизменным.
		\item Операция умножения скаляра на элемент $L$ дистрибутивна
		относительно сложения скаляров.
		\item Операция умножения элемента $L$ на скаляр дистрибутивна
		относительно сложения элементов пространства $L$.
	\end{enumerate}
\end{definition}

\begin{definition}
	Скалярным произведением в векторном пространстве $L$ над полем $\mathbb{C}$
	называется функция $(x, y)$ для элементов (векторов) $x, y \in L$, принимающая
	значения в $\mathbb{C}$ и удовлетворяющая следующим условиям:
	\begin{enumerate}
		\item $(\alpha x_1 + \beta x_2, y) = \alpha (x_1, y) + \beta (x_2, y)$.
		\item $(x, y) = \overline{(y, x)}$.
		\item $(x, x) \geqslant 0$, причем $(x, x) = 0 \Leftrightarrow x = 0$.
	\end{enumerate}
\end{definition}

\begin{definition}
	Нормой в векторном пространстве $L$ над полем вещественных или комплексных
	чисел называется отображение $\norm{\cdot} : L \rightarrow \mathbb{R}^+$,
	обладающее следующими свойствами:
	\begin{enumerate}
		\item $\forall x \in L, \norm{x} \geqslant 0$.
		\item $\norm{x} = 0 \Leftrightarrow x = 0$.
		\item $\forall x, y \in L, \norm{x+y} \leqslant \norm{x} + \norm{y}$ (неравенство
		треугольника).
		\item $\forall \alpha \in \mathbb{R}, \forall x \in L, \norm{\alpha x} = 
		\abs{\alpha}\norm{x}$.
	\end{enumerate}
	Векторное пространство с введенной на нем нормой называется нормированным
	пространством.
\end{definition}
В любом нормированном пространстве можно ввести метрику, определив ее как 
$\rho(x,y) = \norm{y-x}$ (легко проверить, что при этом выполняются все аксиомы
метрики). В этом случае говорят, что метрика порождена нормой.

\begin{definition}
	Банахово пространство — нормированное векторное пространство, полное по
	метрике, порождённой нормой пространства.
\end{definition}

Вычислительная математика чаще всего имеет дело со следующими банаховыми пространствами:
\begin{enumerate}
	\item Множество вещественных чисел $\mathbb{R}$ c нормой $\norm{x} = \abs{x}$.
	\item Множество $C{[a,b]}$ функций, непрерывных на отрезке $[a, b]$ с
	чебышевской нормой $\displaystyle \norm{x}_c = \max_{t \in [a, b]}{\abs{x(t)}}$.
	Заметим, что сходимость по метрике, порожденной этой нормой, называется
	равномерной.
	\item Множество $L_p[a,b]$ функций $x(t)$, определенных на отрезке $[a, b]$ и
	интегрируемых по модулю с $p$-ой степенью. Норма задается формулой
	\[
		\norm{x}_{L_p} = \left(\int\limits_a^b{\abs{x(t)}^p}\,dt\right)^\frac{1}{p}.
	\]
	Сходимость в этой норме называется сходимостью в среднем. В отличие от
	равномерной близости, функции, близкие в среднем, могут мало отличаться на
	большей части области определения и сильно --- на небольших участках. Выбор
	пространства и нормы (а значит, и метрики) обусловлен <<физическими>>
	соображениями, т.е. диктуется ограничениями прикладной области задачи.
	
	Можно показать, что между различными нормами существует определенная связь:
	\[
		\norm{x}_{L_1} \leqslant \norm{x}_{L_2} \leqslant \dots \leqslant \norm{x}_c.
	\]
	Таким образом, чебышевская норма оказывается самой сильной: из сходимости
	в этой норме следует сходимость и в любой норме $\norm{\,\cdot\,}_p$\,.	

	\item Конечномерное пространство $\mathbb{R}^n$ векторов 
	$x = (x_1, x_2, \dots, x_n)$. Норму вектора можно ввести разными способами.
	Довольно часто выбирают одну из гёльдеровых норм: $\displaystyle \norm{x}_p =
	\left(\sum\limits_{i=1}^n{\abs{x_i}^p}\right)^\frac{1}{p}$. Частными ее случаями
	являются
	\[
	\begin{aligned}
	&\norm{x}_2 = \sqrt{\sum\limits_{i=1}^n{x_i^2}} = \sqrt{(x, x)}
	\quad \text{--- евклидова норма,}\\
	&\norm{x}_\infty = \max_{i}{\abs{x_i}}  \quad (p \to \infty).
	\end{aligned}
	\]	

	\item Пространство квадратных матриц порядка $n$. Нормирование этого
	пространства обычно привязывают к нормированию пространства векторов.
	
	Норма матрицы называется согласованной с нормой вектора, если для любой
	матрицы $A$ и любого вектора $x$ справедливо $\norm{Ax} \leqslant
	\norm{A}\cdot\norm{x}$. Говорят, что норма матрицы подчинена норме вектора,
	если
	\[
		\norm{A} = \sup_{x \neq 0}\frac{\norm{Ax}}{\norm{x}}.
	\]
	В соответствии с этим, рассматривают нормы матриц
	\[
		\begin{aligned}
			&\norm{A}_\infty = \max_{i}{\sum_j{\abs{a_{ij}}}},\\
			&\norm{A}_1 = \max_{j}{\sum_i{\abs{a_{ij}}}},\\
			&\norm{A}_2 = \sqrt{\max_i{\lambda^i_{A^*A}}}.
		\end{aligned}
	\]
	Здесь $\lambda^i_D$ - собственные числа матрицы $D$. Последняя норма также
	называется спектральной.	
\end{enumerate}

\begin{problem}
	Построить примеры последовательностей функций, которые сходятся
	в смысле чебышевской нормы, нормы пространства $L_p$.
\end{problem}

\begin{problem}
	Пусть функция $f(x)$ задана таблично. Написать на языке $\mathcal{N}$
	функцию, которая бы приближенно вычисляла нормы $\norm{\,\cdot\,}_c$
	и $\norm{\,\cdot\,}_{L_p}$. Найти готовые реализации (библиотеки, пакеты и проч.)
	для языка $\mathcal{N}$.
\end{problem}

\begin{problem}
	Доказать подчиненность  перечисленных выше норм матриц соответствующим
	векторным нормам.
\end{problem}

\begin{problem}
	Написать на языке $\mathcal{N}$ функцию, которая бы вычисляла нормы 
	$\norm{\,\cdot\,}_\infty$ и $\norm{\,\cdot\,}_p$ для векторов и матриц.
	Найти готовые реализации (библиотеки, пакеты и проч.) для языка $\mathcal{N}$.
\end{problem}


\end{document}











